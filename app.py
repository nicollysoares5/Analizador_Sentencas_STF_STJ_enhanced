import streamlit as st\nimport pandas as pd\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\nfrom io import BytesIO\nfrom fpdf import FPDF\nimport os\n\nst.set_page_config(page_title='Analisador de Senten√ßas STF/STJ', layout='wide',\n                   initial_sidebar_state='expanded')\n\n# --- Styles ---\nst.markdown(\n    '''\n<style>\n.reportview-container {\n    background: linear-gradient(180deg, #f7fbff 0%, #ffffff 100%);\n}\n.sidebar .sidebar-content {\n    background: linear-gradient(#e6f0ff, #ffffff);\n}\n.big-font {\n    font-size:28px !important;\n    font-weight:700;\n}\n.small-muted {\n    color: #6b7280;\n    font-size:12px;\n}\nfooter {visibility: hidden;}\n.custom-footer {\n    padding: 12px 0;\n    color: #0b3d91;\n    text-align: center;\n    font-size: 13px;\n}\n.card {\n    background: white;\n    padding: 12px;\n    border-radius: 8px;\n    box-shadow: 0 1px 3px rgba(12, 35, 60, 0.08);\n}\n</style>\n    ''' ,\n    unsafe_allow_html=True,\n)\n\nst.markdown('<div class="big-font">üßæ Analisador de Senten√ßas do STF / STJ</div>', unsafe_allow_html=True)\nst.markdown('<div class="small-muted">Ferramenta para an√°lise de termos em ementas e visualiza√ß√£o de padr√µes decis√≥rios.</div>', unsafe_allow_html=True)\nst.markdown('---')\n\n# Sidebar\nwith st.sidebar:\n    st.header("Upload de dados")\n    uploaded = st.file_uploader("Carregar CSV (colunas: ID_Decisao, Tribunal, Ementa, Resultado, Data)", type=['csv'])\n    st.markdown("**Exemplo**: `decisoes_stf_stj.csv` com cabe√ßalhos corretos.")\n    st.markdown("---")\n    st.header("Filtros / An√°lise")\n    tribunal_choice = st.selectbox("Filtrar por Tribunal", ["Ambos", "STF", "STJ"], index=0)\n    keywords_input = st.text_input("Termos-chave (separados por v√≠rgula)", value="dano moral, repercuss√£o geral, inconstitucionalidade")\n    extra_stopwords = st.text_area("Stopwords adicionais (uma por linha) ‚Äî para a nuvem de palavras", value="de\na\no\nem\npara\ncom\npor\nque")\n    run_btn = st.button("Rodar An√°lise")\n    st.markdown("---")\n    st.markdown("**Exportar / Deploy**")\n    st.markdown("Depois de enviar para o GitHub, conecte o reposit√≥rio ao Streamlit Cloud para deploy autom√°tico.")\n\n# Helpers\ndef generate_sample_df(n=30):\n    import random\n    sample_ementas = [\n        'Dano moral em contrato de consumo; procedente; responsabilidade do fornecedor',\n        'Habeas corpus improcedente; cerceamento de defesa n√£o configurado',\n        'Repercuss√£o geral reconhecida; inconstitucionalidade parcial',\n        'Contrato banc√°rio e cobran√ßa indevida; procedente',\n        'Quest√£o tribut√°ria; improcedente',\n        'Direito de fam√≠lia; partilha e alimentos; parcialmente procedente',\n        'Licita√ß√£o e responsabilidade; improcedente',\n        'Indeniza√ß√£o por acidente; procedente',\n        'Tutela antecipada concedida; parcialmente procedente',\n        'Recurso especial improvido; n√£o h√° viola√ß√£o federal'\n    ]\n    resultados = ['Procedente','Improcedente','Parcialmente Procedente']\n    tribunais = ['STF','STJ']\n    data = []\n    for i in range(1, n+1):\n        data.append({\n            'ID_Decisao': i,\n            'Tribunal': random.choice(tribunais),\n            'Ementa': random.choice(sample_ementas),\n            'Resultado': random.choice(resultados),\n            'Data': f"202{random.randint(0,4)}-{random.randint(1,12):02d}-{random.randint(1,28):02d}"\n        })\n    return pd.DataFrame(data)\n\ndef load_csv(uploaded_file):\n    if uploaded_file is not None:\n        try:\n            return pd.read_csv(uploaded_file)\n        except Exception:\n            uploaded_file.seek(0)\n            try:\n                return pd.read_csv(uploaded_file, encoding='utf-8-sig')\n            except Exception:\n                uploaded_file.seek(0)\n                return pd.read_csv(uploaded_file, encoding='latin1')\n    else:\n        # try fallback path\n        fallback = "decisoes_stf_stj.csv"\n        if os.path.exists(fallback):\n            try:\n                return pd.read_csv(fallback)\n            except Exception:\n                return pd.read_csv(fallback, encoding='latin1')\n        else:\n            return generate_sample_df()\n\ndef count_keywords(df, col, keywords):\n    kw = [k.strip().lower() for k in keywords if k.strip()]\n    counts = {k:0 for k in kw}\n    mask = [False]*len(df)\n    texts = df[col].fillna('').astype(str)\n    for i, t in enumerate(texts):\n        low = t.lower()\n        for k in kw:\n            if k in low:\n                counts[k] += 1\n                mask[i] = True\n    return counts, mask\n\ndef make_wordcloud(text_series, extra_sw=None):\n    text = " ".join(text_series.fillna('').astype(str).tolist()).lower()\n    stopwords = set(STOPWORDS)\n    if extra_sw:\n        for s in extra_sw:\n            stopwords.add(s.strip().lower())\n    wc = WordCloud(width=800, height=400, background_color='white', stopwords=stopwords, collocations=False).generate(text)\n    return wc\n\ndef fig_to_bytes(fig):\n    buf = BytesIO()\n    fig.savefig(buf, format='png', bbox_inches='tight')\n    buf.seek(0)\n    return buf.getvalue()\n\ndef create_pdf_report(freq_df, matched_df, fig_res_bytes, fig_trib_bytes, wc_bytes):\n    pdf = FPDF(orientation='P', unit='mm', format='A4')\n    pdf.add_page()\n    pdf.set_font("Arial", size=12)\n    pdf.cell(0, 8, "Relat√≥rio de An√°lise - Analisador de Senten√ßas STF/STJ", ln=True)\n    pdf.cell(0, 6, "", ln=True)\n    pdf.set_font("Arial", size=10)\n    pdf.multi_cell(0, 6, "Autores: Nicolly Soares Mota; Maria Eduarda de Bustamante Fontoura", ln=True)\n    pdf.cell(0, 6, "", ln=True)\n\n    pdf.set_font("Arial", size=11)\n    pdf.cell(0, 6, "Frequ√™ncia de termos:", ln=True)\n    pdf.ln(2)\n    for idx, row in freq_df.iterrows():\n        pdf.cell(0, 6, f"{row['Termo']}: {row['Contagem']}", ln=True)\n    pdf.ln(4)\n\n    for img_bytes, title in [(fig_res_bytes, "Distribui√ß√£o de Resultados"), (fig_trib_bytes, "Distribui√ß√£o por Tribunal"), (wc_bytes, "Nuvem de Palavras")]:\n        if img_bytes is None:\n            continue\n        pdf.set_font("Arial", size=11)\n        pdf.cell(0, 6, title, ln=True)\n        fname = "temp_img.png"\n        with open(fname, "wb") as f:\n            f.write(img_bytes)\n        pdf.image(fname, w=170)\n        os.remove(fname)\n        pdf.ln(4)\n\n    pdf.add_page()\n    pdf.set_font("Arial", size=11)\n    pdf.cell(0, 6, "Decis√µes que cont√™m os termos buscados (amostra):", ln=True)\n    pdf.ln(2)\n    cols = list(matched_df.columns)\n    for i, row in matched_df.head(12).iterrows():\n        line = " | ".join(str(row[c]) for c in cols if c in matched_df.columns)\n        pdf.multi_cell(0, 5, line)\n        pdf.ln(1)\n\n    out = BytesIO()\n    out.write(pdf.output(dest='S').encode('latin-1'))\n    out.seek(0)\n    return out.getvalue()\n\n# Load data\ndf = load_csv(uploaded)\n\n# Validate\nrequired = {'ID_Decisao','Tribunal','Ementa','Resultado'}\nif not required.issubset(set(df.columns)):\n    st.error(f"CSV precisa conter colunas: {required}. Colunas encontradas: {list(df.columns)}")\n    st.stop()\n\nst.markdown("### üîé Configura√ß√£o da An√°lise")\ncol1, col2 = st.columns([2,1])\nwith col1:\n    st.write(f"Decis√µes carregadas: **{len(df)}**")\n    if 'Data' in df.columns:\n        st.write(f"Ano - intervalo: {pd.to_datetime(df['Data'], errors='coerce').min()} at√© {pd.to_datetime(df['Data'], errors='coerce').max()}")\nwith col2:\n    st.write("Filtros aplicados:")\n    st.write(f"Tribunal: **{tribunal_choice}**")\n\nst.markdown('---')\n\nif run_btn or st.session_state.get('last_run') is None:\n    st.session_state['last_run'] = True\n\n    keywords = [k.strip().lower() for k in keywords_input.split(',') if k.strip()]\n    extra_sw = [s.strip().lower() for s in extra_stopwords.splitlines() if s.strip()]\n\n    if not keywords:\n        st.warning("Insira ao menos um termo-chave na barra lateral.")\n    else:\n        counts, mask = count_keywords(df_proc, 'Ementa', keywords)\n        freq_df = pd.DataFrame.from_dict(counts, orient='index', columns=['Contagem']).reset_index().rename(columns={'index':'Termo'})\n        matched_df = df_proc.loc[mask, ['ID_Decisao','Tribunal','Resultado','Ementa','Data']].copy() if 'Data' in df_proc.columns else df_proc.loc[mask, ['ID_Decisao','Tribunal','Resultado','Ementa']].copy()\n\n        st.markdown('<div class="card">', unsafe_allow_html=True)\n        st.subheader("üìà Frequ√™ncia de termos")\n        st.table(freq_df)\n        st.markdown('</div>', unsafe_allow_html=True)\n\n        st.subheader("Gr√°ficos")\n        res_counts = df_proc['Resultado'].value_counts().reset_index()\n        res_counts.columns = ['Resultado','Quantidade']\n\n        fig_res = px.bar(res_counts, x='Resultado', y='Quantidade', title='Distribui√ß√£o de Resultados', text='Quantidade')\n        fig_res.update_layout(title=dict(x=0.5), plot_bgcolor='rgba(0,0,0,0)')\n        st.plotly_chart(fig_res, use_container_width=True)\n\n        trib_counts = df_proc['Tribunal'].value_counts().reset_index()\n        trib_counts.columns = ['Tribunal','Quantidade']\n        fig_trib = px.pie(trib_counts, names='Tribunal', values='Quantidade', title='Propor√ß√£o por Tribunal')\n        st.plotly_chart(fig_trib, use_container_width=True)\n\n        st.subheader("Nuvem de palavras")\n        wc = make_wordcloud(df_proc['Ementa'], extra_sw=extra_sw)\n        fig_wc, ax = plt.subplots(figsize=(10,4))\n        ax.imshow(wc, interpolation='bilinear')\n        ax.axis('off')\n        st.pyplot(fig_wc)\n\n        st.subheader("Ranking de palavras (top 20)")\n        all_text = " ".join(df_proc['Ementa'].fillna('').astype(str).tolist()).lower()\n        words = [w for w in all_text.split() if len(w)>3 and w.isalpha() and w not in set(extra_sw)]\n        from collections import Counter\n        ctr = Counter(words)\n        top = pd.DataFrame(ctr.most_common(20), columns=['Palavra','Frequ√™ncia'])\n        st.table(top)\n\n        st.markdown('---')\n        st.subheader("Exportar relat√≥rios")\n\n        csv_bytes = matched_df.to_csv(index=False).encode('utf-8')\n        st.download_button("Download - CSV das decis√µes encontradas", data=csv_bytes, file_name="relatorio_decisoes_encontradas.csv", mime="text/csv")\n\n        freq_csv = freq_df.to_csv(index=False).encode('utf-8')\n        st.download_button("Download - Tabela de frequ√™ncia", data=freq_csv, file_name="tabela_frequencia_termos.csv", mime="text/csv")\n\n        try:\n            img_res = fig_res.to_image(format='png')\n            img_trib = fig_trib.to_image(format='png')\n        except Exception:\n            buf = BytesIO(); fig_res.write_image(buf, format='png'); buf.seek(0); img_res = buf.read()\n            buf2 = BytesIO(); fig_trib.write_image(buf2, format='png'); buf2.seek(0); img_trib = buf2.read()\n\n        buf_wc = BytesIO(); fig_wc.savefig(buf_wc, format='png', bbox_inches='tight'); buf_wc.seek(0); wc_bytes = buf_wc.read()\n\n        pdf_bytes = create_pdf_report(freq_df, matched_df, img_res, img_trib, wc_bytes)\n        st.download_button("Download - Relat√≥rio em PDF", data=pdf_bytes, file_name="relatorio_analise.pdf", mime="application/pdf")\n\nst.markdown("<div class='custom-footer'>¬© 2025 ‚Äî Nicolly Soares Mota & Maria Eduarda de Bustamante Fontoura ‚Äî Analisador de Senten√ßas STF/STJ</div>", unsafe_allow_html=True)\n